# -*- coding: utf-8 -*-
"""ìŠ¤íŠ¸ë¦¼ë¦¿ ì½”ë“œ.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KNDk2-0nZSjR1olOlkkJpgaiYpuwxTqM
"""

import streamlit as st
from PIL import Image
import io
import base64
import os
import json
from openai import OpenAI
import requests
from bs4 import BeautifulSoup
import re
from urllib.parse import urlparse

# =========================================================
# 1) OpenAI Client
# =========================================================
# --- API í‚¤ ì„¤ì • (Secrets ì‚¬ìš©) ---
# ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ ì•ˆì „í•œ í‚¤ ê°€ì ¸ì˜¤ê¸° ë¡œì§
# 1. Secretsì— 'OPENAI_API_KEY'ê°€ ìˆëŠ”ì§€ í™•ì¸
if "OPENAI_API_KEY" in st.secrets:
    api_key = st.secrets["OPENAI_API_KEY"]
    client = OpenAI(api_key=api_key)
# 2. í˜¹ì‹œ ì‚¬ìš©ìê°€ 'API_KEY'ë¼ê³  ì €ì¥í–ˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„ (í˜¸í™˜ì„±)
elif "API_KEY" in st.secrets:
    api_key = st.secrets["API_KEY"]
    client = OpenAI(api_key=api_key)
else:
    # í‚¤ê°€ ì•„ì˜ˆ ì—†ì„ ê²½ìš° ì—ëŸ¬ ë©”ì‹œì§€
    st.error("ğŸš¨ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Streamlit Secretsì— 'OPENAI_API_KEY'ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")
    st.stop()

# =========================================================
# 2) utils: PIL -> base64
# =========================================================
def pil_to_base64(img: Image.Image) -> str:
    buf = io.BytesIO()
    img.save(buf, format="JPEG")
    return base64.b64encode(buf.getvalue()).decode()


# =========================================================
# 3) foods.json ë¡œë“œ/ì €ì¥
# =========================================================
DB_PATH = "foods.json"

def load_db():
    if not os.path.exists(DB_PATH):
        with open(DB_PATH, "w", encoding="utf-8") as f:
            json.dump({}, f, ensure_ascii=False, indent=2)
    return json.load(open(DB_PATH, "r", encoding="utf-8"))


def save_db(db):
    with open(DB_PATH, "w", encoding="utf-8") as f:
        json.dump(db, f, ensure_ascii=False, indent=2)


# =========================================================
# 4) OpenFoodFacts API
# =========================================================
def off_search(food_name: str, max_results=1):
    url = "https://world.openfoodfacts.org/cgi/search.pl"
    params = {
        "search_terms": food_name,
        "search_simple": 1,
        "action": "process",
        "json": 1,
        "page_size": max_results
    }
    try:
        r = requests.get(url, params=params, timeout=8)
        if r.status_code != 200:
            return None
        data = r.json()
        products = data.get("products", [])
        for p in products:
            nutr = p.get("nutriments", {})
            kcal = nutr.get("energy-kcal_100g") or nutr.get("energy_100g")
            if kcal:
                return {
                    "kcal": float(kcal),
                    "carbs_g": nutr.get("carbohydrates_100g"),
                    "protein_g": nutr.get("proteins_100g"),
                    "fat_g": nutr.get("fat_100g"),
                    "default_g": 100.0
                }
        return None
    except:
        return None


# =========================================================
# 5) ì•ˆì „ ìŠ¤í¬ë˜í•‘ (robots.txt ì¤€ìˆ˜)
# =========================================================
USER_AGENT = "Mozilla/5.0 (compatible; FoodCalorieBot/1.0)"

ALLOW_DOMAINS = [
    "cookpad.com", "allrecipes.com", "bbcgoodfood.com",
    "unsplash.com", "wikimedia.org"
]

def robots_allows(url):
    try:
        parsed = urlparse(url)
        base = f"{parsed.scheme}://{parsed.netloc}/robots.txt"
        r = requests.get(base, timeout=5)
        if r.status_code != 200:
            return False
        txt = r.text.lower()
        return "allow: /" in txt or "allow: / " in txt
    except:
        return False


def safe_scrape(food_name: str):
    q = f"{food_name} calories"
    try:
        search = requests.get(
            "https://duckduckgo.com/html/",
            params={"q": q},
            timeout=5,
            headers={"User-Agent": USER_AGENT}
        )
        soup = BeautifulSoup(search.text, "html.parser")
        links = [a["href"] for a in soup.select("a.result__a") if any(d in a["href"] for d in ALLOW_DOMAINS)]
        for url in links[:3]:
            if not robots_allows(url):
                continue
            r = requests.get(url, timeout=5)
            text = r.text
            m = re.search(r'([0-9]{2,4})\s?kcal', text, re.I)
            if not m:
                continue
            kcal = float(m.group(1))
            return {
                "kcal": kcal,
                "carbs_g": None,
                "protein_g": None,
                "fat_g": None,
                "default_g": 100.0
            }
    except:
        return None
    return None


# =========================================================
# 6) ì˜ì–‘ ì •ë³´ í™•ë³´
# =========================================================
def ensure_nutrition_entry(food_name: str):
    db = load_db()
    key = food_name.lower()

    if key in db and db[key].get("kcal"):
        return db[key]

    # OpenFoodFacts
    off = off_search(food_name)
    if off:
        db[key] = off
        save_db(db)
        return off

    # Safe scrape
    web = safe_scrape(food_name)
    if web:
        db[key] = web
        save_db(db)
        return web

    return None


# =========================================================
# 7) OpenAI Visionìœ¼ë¡œ ìŒì‹ ì˜ˆì¸¡
# =========================================================
def predict_food_names(image: Image.Image, top_k=3):
    img_b64 = pil_to_base64(image)
    prompt = (
        "ì´ ìŒì‹ ì‚¬ì§„ì—ì„œ ìŒì‹ ì´ë¦„ì„ 3ê°œ ì´í•˜ë¡œ í•œêµ­ì–´ë¡œ ì˜ˆì¸¡í•´ì¤˜. "
        "ë°˜ë“œì‹œ ìŒì‹ ì´ë¦„ë§Œ ë°˜í™˜í•´."
    )

    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "You are a food recognition model."},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": f"data:image/jpeg;base64,{img_b64}"}
                ]
            }
        ],
        max_tokens=120
    )

    out = res.choices[0].message.content
    cleaned = out.replace("[", "").replace("]", "").replace("'", "").replace('"', "")
    names = cleaned.replace(",", " ").split()
    return names[:top_k]


# =========================================================
# 8) ì¹¼ë¡œë¦¬ ê³„ì‚°
# =========================================================
def calculate_nutrition(entry, grams):
    factor = grams / 100.0
    return {
        "kcal": round(entry.get("kcal", 0) * factor, 1),
        "carbs_g": entry.get("carbs_g"),
        "protein_g": entry.get("protein_g"),
        "fat_g": entry.get("fat_g"),
        "grams": grams
    }


# =========================================================
# 9) Streamlit UI
# =========================================================
st.title("ğŸ½ï¸ Streamlit + OpenAI Vision ì¹¼ë¡œë¦¬ ê³„ì‚°ê¸°")

uploaded = st.file_uploader("ğŸ“· ìŒì‹ ì‚¬ì§„ ì—…ë¡œë“œ", type=["jpg", "jpeg", "png"])
manual_name = st.text_input("ğŸœ ìŒì‹ ì´ë¦„ ì§ì ‘ ì…ë ¥ (ì„ íƒ)")
grams = st.number_input("âš–ï¸ ê·¸ë¨ ì…ë ¥", min_value=1.0, max_value=3000.0, value=100.0)
btn = st.button("ì˜ˆì¸¡í•˜ê¸°")

if btn:
    if not uploaded:
        st.error("ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        st.stop()

    img = Image.open(uploaded).convert("RGB")
    st.image(img, use_column_width=True, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€")

    # ìŒì‹ ì´ë¦„ ìš°ì„ ìˆœìœ„: ì§ì ‘ ì…ë ¥ > Vision ì˜ˆì¸¡
    if manual_name.strip():
        candidates = [manual_name.strip()]
    else:
        st.info("ğŸ” OpenAI Visionìœ¼ë¡œ ìŒì‹ ì´ë¦„ ì˜ˆì¸¡ ì¤‘â€¦")
        candidates = predict_food_names(img)
        st.write("ğŸ“Œ Vision ì˜ˆì¸¡:", candidates)

    # Nutrition lookup
    found = None
    final_name = None

    for name in candidates:
        entry = ensure_nutrition_entry(name)
        if entry:
            found = entry
            final_name = name
            break

    if not found:
        st.error("âŒ ì–´ë–¤ ìŒì‹ì—ì„œë„ ì˜ì–‘ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # ê³„ì‚°
    result = calculate_nutrition(found, grams)

    # ì¶œë ¥
    st.subheader(f"ğŸœ ìµœì¢… ìŒì‹: {final_name}")
    st.markdown(f"""
    ### ğŸ“Š ì˜ì–‘ ë¶„ì„
    - ì¹¼ë¡œë¦¬: **{result['kcal']} kcal**
    - íƒ„ìˆ˜í™”ë¬¼: {result['carbs_g']}
    - ë‹¨ë°±ì§ˆ: {result['protein_g']}
    - ì§€ë°©: {result['fat_g']}
    - ì‚¬ìš© ê·¸ë¨: {result['grams']} g
    """)

    st.success("ì™„ë£Œ ğŸ‰")
