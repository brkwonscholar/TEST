import streamlit as st
from openai import OpenAI
from PIL import Image
import io
import os
from dotenv import load_dotenv
import base64

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (API í‚¤)
load_dotenv()

# --- ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="ëƒ‰ì¥ê³  ì† ì…°í”„", layout="wide")

# --- API í‚¤ ì„¤ì • (Secrets ì‚¬ìš©) ---
# ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ ì•ˆì „í•œ í‚¤ ê°€ì ¸ì˜¤ê¸° ë¡œì§
# 1. Secretsì— 'OPENAI_API_KEY'ê°€ ìˆëŠ”ì§€ í™•ì¸
if "OPENAI_API_KEY" in st.secrets:
    api_key = st.secrets["OPENAI_API_KEY"]
    client = OpenAI(api_key=api_key)
# 2. í˜¹ì‹œ ì‚¬ìš©ìê°€ 'API_KEY'ë¼ê³  ì €ì¥í–ˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„ (í˜¸í™˜ì„±)
elif "API_KEY" in st.secrets:
    api_key = st.secrets["API_KEY"]
    client = OpenAI(api_key=api_key)
else:
    # í‚¤ê°€ ì•„ì˜ˆ ì—†ì„ ê²½ìš° ì—ëŸ¬ ë©”ì‹œì§€
    st.error("ğŸš¨ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Streamlit Secretsì— 'OPENAI_API_KEY'ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")
    st.stop()

# ì‚¬ì´ë“œë°” (ì‚¬ìš©ì ì„¤ì •)
with st.sidebar:
    st.header("ì‚¬ìš©ì ì„¤ì • âš™ï¸")
    # ì´ˆê¸° ìœ í†µê¸°í•œ ì„ë°• ì¬ë£Œ ì„¤ì • (ë°ëª¨ë¥¼ ìœ„í•´ ìˆ˜ë™ ì„¤ì •)
    urgent_ingredient = st.text_input(
        "ê¸´ê¸‰ ì†Œë¹„ ì¬ë£Œ (ì„ íƒ)",
        "ì–‘íŒŒ, ë‘ë¶€"
    )
    # ê°œì¸ ê¸°í˜¸ ì„¤ì •
    preference = st.radio(
        "ìš”ë¦¬ ìŠ¤íƒ€ì¼ ì„ í˜¸ë„",
        ['ê¸°ë³¸', 'í•œì‹', 'ê±´ê°•ì‹', 'ê°„ë‹¨í•œ ìš”ë¦¬', 'ë§¤ìš´ë§›',]
    )
    
    st.markdown("---")
    st.info("ğŸ’¡ **ì‚¬ìš©ë²•:** ëƒ‰ì¥ê³  ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  'ì¬ë£Œ ì¸ì‹ ë° ë ˆì‹œí”¼ ì œì•ˆ' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")
    st.subheader("í”„ë¡œì íŠ¸ ì •ë³´")
    st.markdown(f"**ë¶„ë°˜:** 38ë¶„ë°˜")
    st.markdown(f"**í•™ë²ˆ/ì´ë¦„:** 20241481 ìœ¤í•œë¹›")
    st.markdown(f"**ê¸°ìˆ :** GPT-4 Vision, Streamlit")

# --- ë©”ì¸ í˜ì´ì§€ ---
st.title("ğŸ§Š ëƒ‰ì¥ê³  ì† ì…°í”„ - AI ë§ì¶¤ ë ˆì‹œí”¼ ì œì•ˆ")
st.markdown("ë‚¨ì€ ì¬ë£Œë¥¼ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ê³  ê°œì¸ ì„ í˜¸ë„ì— ë§ëŠ” ë§ì¶¤í˜• ë ˆì‹œí”¼ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'recognized_ingredients' not in st.session_state:
    st.session_state.recognized_ingredients = None
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

# ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ëƒ‰ì¥ê³  ë‚´ë¶€ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["jpg", "jpeg", "png"])

col1, col2 = st.columns([1, 2])

with col1:
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption="ì—…ë¡œë“œëœ ëƒ‰ì¥ê³  ì‚¬ì§„", use_column_width=True)

        # ì´ë¯¸ì§€ íŒŒì¼ì„ Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ APIì— ì „ë‹¬
        with io.BytesIO() as buffer:
            image.save(buffer, format="JPEG")
            base64_image = base64.b64encode(buffer.getvalue()).decode('utf-8')

        # GPT Vision APIì— ì „ë‹¬í•  ì´ë¯¸ì§€ ê°ì²´ ìƒì„±
        image_content = {
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{base64_image}"
            }
        }
    else:
        # ì´ë¯¸ì§€ê°€ ì—†ì„ ë•Œ ë©”ì‹œì§€
        st.warning("ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        st.session_state.recognized_ingredients = None
        st.session_state.chat_history = []


# --- í•µì‹¬ ë¡œì§: ì¬ë£Œ ì¸ì‹ ë° ë ˆì‹œí”¼ ì œì•ˆ ---

with col2:
    if st.button("ì¬ë£Œ ì¸ì‹ ë° ë ˆì‹œí”¼ ì œì•ˆ ì‹œì‘ ğŸš€", disabled=uploaded_file is None):
        with st.spinner("AIê°€ ëƒ‰ì¥ê³  ì† ì¬ë£Œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            
            # 1. Vision ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‹ì¬ë£Œ ì¸ì‹
            vision_prompt = """
            ë‹¹ì‹ ì€ ìµœê³ ì˜ ëƒ‰ì¥ê³  ì¬ë£Œ ê´€ë¦¬ ì…°í”„ì…ë‹ˆë‹¤. 
            ì—…ë¡œë“œëœ ëƒ‰ì¥ê³  ì‚¬ì§„ì„ ë³´ê³  ì–´ë–¤ ì‹ì¬ë£Œë“¤ì´ ìˆëŠ”ì§€ ìƒì„¸í•˜ê²Œ ë¦¬ìŠ¤íŠ¸ì—…í•´ì£¼ì„¸ìš”. 
            ì¬ë£Œ ì´ë¦„ ì™¸ì— ë¶ˆí•„ìš”í•œ ì„œë¡ /ê²°ë¡  ì—†ì´ ì¬ë£Œ ë¦¬ìŠ¤íŠ¸ë§Œ í…ìŠ¤íŠ¸ë¡œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•´ì¤ë‹ˆë‹¤.
            """
            
            try:
                response = client.chat.completions.create(
                    model="gpt-4o-mini", # ì´ë¯¸ì§€ ë° í…ìŠ¤íŠ¸ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•œ ëª¨ë¸ ì‚¬ìš©
                    messages=[
                        {"role": "user", "content": [
                            {"type": "text", "text": vision_prompt},
                            image_content
                        ]}
                    ]
                )
                
                recognized_ingredients_text = response.choices[0].message.content.strip()
                st.session_state.recognized_ingredients = recognized_ingredients_text
                
            except Exception as e:
                st.error(f"ì¬ë£Œ ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.stop()

            # 2. LLMì„ ì‚¬ìš©í•˜ì—¬ ë§ì¶¤ ë ˆì‹œí”¼ ìƒì„± ë° ëŒ€í™” ì‹œì‘
            ingredients = st.session_state.recognized_ingredients
            
            # ì‚¬ìš©ì ë§ì¶¤ í”„ë¡¬í”„íŠ¸ ìƒì„±
            llm_prompt = f"""
            ë°©ê¸ˆ ì¸ì‹ëœ ëƒ‰ì¥ê³  ì¬ë£ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: {ingredients}
            ê¸´ê¸‰ ì†Œë¹„ê°€ í•„ìš”í•œ ì¬ë£ŒëŠ” "{urgent_ingredient}"ì…ë‹ˆë‹¤.
            ì‚¬ìš©ìì˜ ì„ í˜¸ë„ëŠ” "{preference}"ì…ë‹ˆë‹¤.

            ìœ„ ì¬ë£Œì™€ ì„ í˜¸ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ìš”ë¦¬ 1ê°€ì§€ì˜ ë§ì¶¤í˜• ë ˆì‹œí”¼ë¥¼ ë‹¨ê³„ë³„ë¡œ ì œì•ˆí•´ì£¼ì„¸ìš”.
            ì œì•ˆëœ ìš”ë¦¬ ì´ë¦„, í•„ìš”í•œ ì¶”ê°€ ì¬ë£Œ, ë‹¨ê³„ë³„ ì¡°ë¦¬ë²•ì„ í¬í•¨í•˜ì—¬ ì¹œì ˆí•˜ê³  ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
            """
            
            try:
                recipe_response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ì ëƒ‰ì¥ê³  ì¬ë£Œë¥¼ í™œìš©í•˜ì—¬ ë§ì¶¤ ë ˆì‹œí”¼ë¥¼ ì œì•ˆí•˜ëŠ” ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ ì…°í”„ì…ë‹ˆë‹¤. ì–¸ì œë‚˜ ëŒ€í™”í˜•ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."},
                        {"role": "user", "content": llm_prompt}
                    ]
                )
                
                ai_initial_response = recipe_response.choices[0].message.content
                
                # ëŒ€í™” ë‚´ì—­ ì—…ë°ì´íŠ¸ ë° í‘œì‹œ
                st.session_state.chat_history = [
                    {"role": "assistant", "content": ai_initial_response}
                ]
                
                # ì¬ë£Œ ì¸ì‹ ê²°ê³¼ë¥¼ ë”°ë¡œ í‘œì‹œ
                st.success("âœ… ì¬ë£Œ ì¸ì‹ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. AI ì…°í”„ê°€ ë ˆì‹œí”¼ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤!")
                st.markdown(f"**ğŸ‘‰ ì¸ì‹ëœ ì¬ë£Œ ëª©ë¡:** {ingredients}")
                st.markdown("---")

            except Exception as e:
                st.error(f"ë ˆì‹œí”¼ ì œì•ˆ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.stop()

# --- ëŒ€í™”í˜• ë ˆì‹œí”¼ ì œì•ˆ ---

st.subheader("AI ì…°í”„ì™€ì˜ ëŒ€í™” ğŸ’¬")

if st.session_state.chat_history:
    # ê¸°ì¡´ ëŒ€í™” í‘œì‹œ
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    user_input = st.chat_input("ì´ ë ˆì‹œí”¼ì— ëŒ€í•´ ë” ê¶ê¸ˆí•œ ì ì´ ìˆë‚˜ìš”? (ì˜ˆ: 'ì¶”ê°€ ì¬ë£Œ ì—†ì´ ë§Œë“¤ ìˆ˜ ìˆë‚˜ìš”?', 'ë§¤ìš´ë§›ì„ ì¤„ì´ëŠ” ë°©ë²•ì€ìš”?')")

    if user_input:
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.spinner("AI ì…°í”„ê°€ ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
            
            # ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ API í˜¸ì¶œ
            messages_for_api = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ì ëƒ‰ì¥ê³  ì¬ë£Œë¥¼ í™œìš©í•˜ì—¬ ë§ì¶¤ ë ˆì‹œí”¼ë¥¼ ì œì•ˆí•˜ëŠ” ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ ì…°í”„ì…ë‹ˆë‹¤. ì–¸ì œë‚˜ ëŒ€í™”í˜•ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."},
                # ê¸°ì¡´ ëŒ€í™” ë‚´ì—­ ì¶”ê°€
                *st.session_state.chat_history
            ]

            try:
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=messages_for_api
                )
                ai_response = response.choices[0].message.content
                st.session_state.chat_history.append({"role": "assistant", "content": ai_response})
                
                # ìƒˆë¡œìš´ ë‹µë³€ í‘œì‹œ
                with st.chat_message("assistant"):
                    st.markdown(ai_response)

            except Exception as e:
                st.error(f"ëŒ€í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# --- ì¥ë³´ê¸° ë¦¬ìŠ¤íŠ¸ ë° ì†Œë¹„ ê¸°ë¡ (ë°ëª¨ìš©) ---

st.markdown("---")
st.subheader("ê´€ë¦¬ ê¸°ëŠ¥ ğŸ›’")
st.markdown("*í–¥í›„ êµ¬í˜„ ëª©í‘œ: ì¬ë£Œ ì†Œë¹„ ê¸°ë¡ ë° ìë™ ì¥ë³´ê¸° ë¦¬ìŠ¤íŠ¸ ìƒì„±*")

if st.button("ì¥ë³´ê¸° ë¦¬ìŠ¤íŠ¸ ìƒì„±"):
    with st.spinner("ì¥ë³´ê¸° ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤..."):
        # LLMì„ í™œìš©í•˜ì—¬ ì¥ë³´ê¸° ë¦¬ìŠ¤íŠ¸ ì œì•ˆ
        shopping_list_prompt = f"""
        í˜„ì¬ ì¸ì‹ëœ ëƒ‰ì¥ê³  ì¬ë£Œ ({st.session_state.recognized_ingredients if st.session_state.recognized_ingredients else 'ì—†ìŒ'})ì™€
        ì„ í˜¸í•˜ëŠ” ìš”ë¦¬ ìŠ¤íƒ€ì¼ ({preference})ì„ ê³ ë ¤í•˜ì—¬, ë‹¤ìŒ ì£¼ ì‹ì‚¬ë¥¼ ìœ„í•œ í•„ìˆ˜ ì¶”ê°€ ì¬ë£Œ 5ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì œì•ˆí•´ì£¼ì„¸ìš”.
        """
        try:
            shop_response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "user", "content": shopping_list_prompt}
                ]
            )
            st.success("âœ… ì¥ë³´ê¸° ë¦¬ìŠ¤íŠ¸ê°€ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.markdown(shop_response.choices[0].message.content)
        except Exception as e:
            st.error(f"ì¥ë³´ê¸° ë¦¬ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
